{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def printmem():\n",
    "#     allocated = torch.cuda.memory_allocated()\n",
    "#     cached = torch.cuda.memory_cached()\n",
    "#     print('Allocated:', str(allocated), '['+str(round(allocated/1000000000,3))+' GB]')\n",
    "#     print('   Cached:', str(cached), '['+str(round(cached/1000000000,3))+' GB]')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "    \n",
    "# printmem()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from criteria import KIDMindLoss\n",
    "from helpers import Trainer\n",
    "from helpers import Logger\n",
    "from helpers import Trial\n",
    "from mibi_dataloader import KID_Data\n",
    "from modules import Mind_of_KID\n",
    "import utils\n",
    "\n",
    "# printmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading\n",
      "There are  10000 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "main_dir = '/Volumes/ALEX USB/project_KID/'\n",
    "train_dir = main_dir + 'KID_memory/'\n",
    "# test_dir = main_dir + 'low_AD/'\n",
    "modl_dir = main_dir + 'models/'\n",
    "rslt_dir = main_dir + 'results/'\n",
    "\n",
    "train_ds = KID_Data(folder=train_dir, crop=55, scale=1, stride=1)\n",
    "# test_ds = MIBIData(folder=test_dir, crop=32, scale=10, stride=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "laddernet_args = dict()\n",
    "\n",
    "# laddernet_args['batchnorm'] = False\n",
    "\n",
    "kidmind = Mind_of_KID()\n",
    "# kidmind = Mind_of_KID.load_model('/Volumes/ALEX USB/project_KID/models/2019Aug17_15-33-34/', 'model_777')\n",
    "# laddernet.cuda()\n",
    "# print(owlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidmind_logger = Logger(['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidmind_trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LadderNet training parameters\n",
    "kidmind_train_args = dict()\n",
    "kidmind_train_args['lr'] = 0.01\n",
    "kidmind_train_args['batch_size'] = 100\n",
    "kidmind_train_args['epochs'] = 5\n",
    "kidmind_train_args['report'] = 5\n",
    "kidmind_train_args['crop'] = 55\n",
    "kidmind_train_args['clip'] = None\n",
    "kidmind_train_args['decay'] = 0\n",
    "kidmind_train_args['restart'] = False\n",
    "kidmind_train_args['epoch_frac'] = 1\n",
    "# laddernet_train_args['decay'] = 1e-5\n",
    "\n",
    "# LadderNet loss parameters\n",
    "kidmind_loss_args = {\n",
    "    'alpha': 1,\n",
    "    'beta': 1,\n",
    "    'gamma': 0,\n",
    "    'delta': 0.1\n",
    "}\n",
    "\n",
    "train_ds.set_crop(kidmind_train_args['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Minibatch:58/99 > < loss: 0.92647, inv_loss: 0.87401, for_loss: 0.21361, sen_loss: 0.05203, per_loss: 0.00431,                                                                                                       "
     ]
    }
   ],
   "source": [
    "kidmind_train_args['continue'] = False\n",
    "# laddernet.set_noise_std(0)\n",
    "# laddernet.set_num_steps(10)\n",
    "kidmind_criterion = KIDMindLoss(**kidmind_loss_args)\n",
    "kidmind_trainer.train(kidmind, train_ds, kidmind_criterion, kidmind_logger, '/Volumes/ALEX USB/project_KID/models/', **kidmind_train_args)\n",
    "# print()\n",
    "# torch.cuda.empty_cache()\n",
    "# printmem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidmind.eval()\n",
    "batch = train_ds.get_samples([np.random.randint(10000)])\n",
    "imgx = batch['s_i'][0,:,:,:].transpose(0,1).transpose(1,2)\n",
    "y = kidmind.forward(**batch)\n",
    "imgy = y['~s_i'][0,:,:,:].transpose(0,1).transpose(1,2).detach()\n",
    "\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "plt.imshow(imgx)\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "plt.imshow(imgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(9)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
