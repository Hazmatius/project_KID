{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Criteria import CateyeLoss\n",
    "from Helpers import Trainer\n",
    "from Helpers import Logger\n",
    "from MIBI_Dataloader import MIBIData\n",
    "from Modules import Cateye\n",
    "import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Point35.tiff', 'Point26.tiff', 'Point21.tiff', 'Point25.tiff', 'Point31.tiff', 'Point34.tiff', 'Point22.tiff', 'Point27.tiff']\n",
      "\n",
      "Image channels: 29\n",
      "   Image width: 1024\n",
      "  Image height: 1024\n",
      "\n",
      "Loading.......0.0%\n",
      "Loading.......12.5%\n",
      "Loading.......25.0%\n",
      "Loading.......37.5%\n",
      "Loading.......50.0%\n",
      "Loading.......62.5%\n",
      "Loading.......75.0%\n",
      "Loading.......87.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazmat/GitHub/Hawkeye/MIBI_Dataloader.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(images), tifs, num_channels, data_width, data_height\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Point2.tiff', 'Point12.tiff', 'Point9.tiff', 'Point18.tiff', 'Point10.tiff', 'Point14.tiff', 'Point13.tiff', 'Point15.tiff', 'Point20.tiff', 'Point8.tiff']\n",
      "\n",
      "Image channels: 29\n",
      "   Image width: 1024\n",
      "  Image height: 1024\n",
      "\n",
      "Loading.......0.0%\n",
      "Loading.......10.0%\n",
      "Loading.......20.0%\n",
      "Loading.......30.0%\n",
      "Loading.......40.0%\n",
      "Loading.......50.0%\n",
      "Loading.......60.0%\n",
      "Loading.......70.0%\n",
      "Loading.......80.0%\n",
      "Loading.......90.0%\n",
      "There are  69192 samples\n",
      "['Point24.tiff', 'Point28.tiff', 'Point33.tiff', 'Point23.tiff', 'Point29.tiff', 'Point30.tiff', 'Point32.tiff']\n",
      "\n",
      "Image channels: 29\n",
      "   Image width: 1024\n",
      "  Image height: 1024\n",
      "\n",
      "Loading.......0.0%\n",
      "Loading.......14.285714285714286%\n",
      "Loading.......28.571428571428573%\n",
      "Loading.......42.857142857142854%\n",
      "Loading.......57.142857142857146%\n",
      "Loading.......71.42857142857143%\n",
      "Loading.......85.71428571428571%\n",
      "['Point4.tiff', 'Point1.tiff', 'Point7.tiff', 'Point17.tiff', 'Point19.tiff', 'Point16.tiff', 'Point5.tiff', 'Point6.tiff', 'Point11.tiff', 'Point3.tiff']\n",
      "\n",
      "Image channels: 29\n",
      "   Image width: 1024\n",
      "  Image height: 1024\n",
      "\n",
      "Loading.......0.0%\n",
      "Loading.......10.0%\n",
      "Loading.......20.0%\n",
      "Loading.......30.0%\n",
      "Loading.......40.0%\n",
      "Loading.......50.0%\n",
      "Loading.......60.0%\n",
      "Loading.......70.0%\n",
      "Loading.......80.0%\n",
      "Loading.......90.0%\n",
      "There are  65348 samples\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "main_dir = '/home/hazmat/Documents/mayonoise/'\n",
    "train_dir = main_dir + 'data/train/'\n",
    "test_dir = main_dir + 'data/test/'\n",
    "modl_dir = main_dir + 'models/'\n",
    "rslt_dir = main_dir + 'results/'\n",
    "labels = {\n",
    "    'early': torch.tensor([0]),\n",
    "    'late' : torch.tensor([1])\n",
    "}\n",
    "\n",
    "train_ds = MIBIData(folder=train_dir, labels=labels, crop=32)\n",
    "test_ds = MIBIData(folder=test_dir, labels=labels, crop=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazmat/GitHub/Hawkeye/Modules.py:62: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  torch.nn.init.uniform(self.conv_logvar.weight, -init_weight, init_weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cateye(\n",
       "  (encoder): VAE_Encoder(\n",
       "    (filter): Sequential(\n",
       "      (conv_0): Conv2d(29, 22, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_0): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (conv_mu): Conv2d(22, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (conv_logvar): Conv2d(22, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (defilter): Sequential(\n",
       "      (conv_0): Conv2d(16, 22, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_0): PReLU(num_parameters=1)\n",
       "      (conv_1): Conv2d(22, 29, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_1): PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (mlp): Sequential(\n",
       "      (fc_0): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (reparam): Reparam()\n",
       "  (avgpool): Global_Avg_Pool()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cateye model parameters\n",
    "cateye_model_args = {}\n",
    "cateye_model_args['kernel'] = 5\n",
    "cateye_model_args['in_dim'] = 29\n",
    "cateye_model_args['code_dim'] = 16\n",
    "cateye_model_args['class_dim'] = 2\n",
    "cateye_model_args['encoder_layers'] = 2\n",
    "cateye_model_args['decoder_layers'] = 2\n",
    "cateye_model_args['attention_layers'] = 2\n",
    "cateye_model_args['class_layers'] = 1\n",
    "\n",
    "cateye = Cateye(**cateye_model_args)\n",
    "cateye.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cateye_trainer = Trainer()\n",
    "cateye_logger = Logger({'loss':(list(),list())})\n",
    "\n",
    "variational = True\n",
    "# Cateye training parameters\n",
    "cateye_train_args = {}\n",
    "cateye_train_args['lr'] = 0.001\n",
    "cateye_train_args['batch_size'] = 1000\n",
    "cateye_train_args['epochs'] = 1\n",
    "cateye_train_args['report'] = 50\n",
    "cateye_train_args['crop'] = 64\n",
    "cateye_train_args['clip'] = 1\n",
    "cateye_train_args['scale'] = 1\n",
    "cateye_train_args['decay'] = 0\n",
    "# Cateye loss parameters\n",
    "cateye_loss_args = {}\n",
    "cateye_loss_args['alpha'] = 1 # Cross-entropy classification loss\n",
    "cateye_loss_args['beta'] = 1 # KL-divergence\n",
    "cateye_loss_args['gamma'] = 0.01 # MSE reconstruction loss\n",
    "if not variational:\n",
    "  cateye_train_args['scale'] = 0\n",
    "  cateye_loss_args['beta'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hazmat/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/hazmat/GitHub/Hawkeye/MIBI_Dataloader.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'x': torch.tensor(sample).float().cuda(),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Minibatch:0 > < loss: 0.56674, class_loss: 0.12822, recon_loss: 35.23959, kldiv_loss: 0.08612, \n",
      "    Minibatch:1 > < loss: 1.77821, class_loss: 0.19209, recon_loss: 153.20486, kldiv_loss: 0.05407, \n",
      "    Minibatch:2 > < loss: 1.44021, class_loss: 0.13674, recon_loss: 125.21777, kldiv_loss: 0.05129, \n",
      "    Minibatch:3 > < loss: 0.71779, class_loss: 0.10837, recon_loss: 54.8648, kldiv_loss: 0.06078, \n",
      "    Minibatch:4 > < loss: 0.76732, class_loss: 0.14695, recon_loss: 52.01468, kldiv_loss: 0.10023, \n",
      "    Minibatch:5 > < loss: 0.95452, class_loss: 0.16149, recon_loss: 66.82743, kldiv_loss: 0.12476, \n",
      "    Minibatch:6 > < loss: 0.78045, class_loss: 0.11207, recon_loss: 55.16818, kldiv_loss: 0.1167, \n",
      "    Minibatch:7 > < loss: 0.60174, class_loss: 0.11593, recon_loss: 39.30442, kldiv_loss: 0.09277, \n",
      "    Minibatch:8 > < loss: 0.66831, class_loss: 0.11375, recon_loss: 48.42159, kldiv_loss: 0.07035, \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-75197308d897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcateye_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCateyeLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcateye_loss_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcateye_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcateye\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcateye_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcateye_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcateye_train_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/GitHub/Hawkeye/Helpers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_set, criterion, logger, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mminibatch_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mbatch_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mbatch_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_vars\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mmodel_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/Hawkeye/MIBI_Dataloader.py\u001b[0m in \u001b[0;36mget_next_minibatch\u001b[0;34m(self, minibatch_size)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m# legacy function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/Hawkeye/MIBI_Dataloader.py\u001b[0m in \u001b[0;36mget_samples\u001b[0;34m(self, sample_indices, flatten)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         samples = {\n",
      "\u001b[0;32m~/GitHub/Hawkeye/MIBI_Dataloader.py\u001b[0m in \u001b[0;36mget_image\u001b[0;34m(self, sample_index)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvind2sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mimg_crop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoint_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_rotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/Hawkeye/MIBI_Dataloader.py\u001b[0m in \u001b[0;36mrandom_rotate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cateye_criterion = CateyeLoss(**cateye_loss_args)\n",
    "cateye_trainer.train(cateye, train_ds, cateye_criterion, cateye_logger, **cateye_train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cateye(\n",
       "  (encoder): VAE_Encoder(\n",
       "    (filter): Sequential(\n",
       "      (conv_0): Conv2d(29, 22, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_0): PReLU(num_parameters=1)\n",
       "    )\n",
       "    (conv_mu): Conv2d(22, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (conv_logvar): Conv2d(22, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (defilter): Sequential(\n",
       "      (conv_0): Conv2d(16, 22, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_0): PReLU(num_parameters=1)\n",
       "      (conv_1): Conv2d(22, 29, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (prelu_1): PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (mlp): Sequential(\n",
       "      (fc_0): Linear(in_features=16, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (sigmoid): Sigmoid()\n",
       "  (reparam): Reparam()\n",
       "  (avgpool): Global_Avg_Pool()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cateye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sigmoid()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cateye.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(5)\n",
    "isinstance(t, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.10298"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.102983, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = 'i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if temp == 'sigmoid':\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "temp = dict()\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
